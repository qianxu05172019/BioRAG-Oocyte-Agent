import streamlit as st
from src.document_loader import DocumentProcessor
from src.embeddings import VectorStoreManager
from src.rag_pipeline import RAGPipeline
import os

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Oocyte Expert",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
    }
    .assistant-message {
        background-color: #f5f5f5;
    }
    .citation {
        font-size: 0.8rem;
        color: #666;
        border-left: 3px solid #ccc;
        padding-left: 1rem;
        margin-top: 0.5rem;
    }
    </style>
    """, unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'rag_pipeline' not in st.session_state:
    st.session_state.rag_pipeline = None
if 'is_initialized' not in st.session_state:
    st.session_state.is_initialized = False
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ§¬ Oocyte Expert")
    st.markdown("""
    ### About
    This AI assistant specializes in oocyte maturation research, powered by:
    - Comprehensive literature database
    - Advanced language understanding
    - Real-time citation tracking
    """)
    
    # çŸ¥è¯†åº“çŠ¶æ€æ˜¾ç¤º
    if st.session_state.is_initialized:
        st.success("Knowledge Base: Active âœ…")
    else:
        st.warning("Knowledge Base: Loading...")
    
    # æ·»åŠ é‡ç½®æŒ‰é’®
    if st.button("Reset System"):
        st.session_state.chat_history = []
        st.experimental_rerun()

# ä¸»ç•Œé¢å†…å®¹
st.title("Oocyte Research Assistant")

# === çŸ¥è¯†åº“åˆå§‹åŒ–éƒ¨åˆ†ï¼ˆæ–°æ·»åŠ ï¼‰===
if not st.session_state.is_initialized:
    with st.spinner("Initializing knowledge base..."):
        try:
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
            vector_store_manager = VectorStoreManager()
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„å¤„ç†çš„å‘é‡å­˜å‚¨
            try:
                vector_store = vector_store_manager.load_vector_store("data/chroma_db")
                st.session_state.vector_store = vector_store
            except ValueError:
                st.error("Vector store not found. Please process PDF documents first.")
                st.stop()
            
            # åˆå§‹åŒ–RAG pipeline
            st.session_state.rag_pipeline = RAGPipeline(vector_store)
            st.session_state.is_initialized = True
            
        except Exception as e:
            st.error(f"Error initializing system: {str(e)}")
            st.stop()

# æ˜¾ç¤ºèŠå¤©å†å²
for idx, message in enumerate(st.session_state.chat_history):
    with st.chat_message(message["role"]):
        st.write(message["content"])
        if "citations" in message and message["citations"]:
            with st.expander("View Citations"):
                for citation in message["citations"]:
                    st.markdown(f"*{citation}*")

# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("Ask your question about oocyte research..."):
    # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°å†å²
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    # å¤„ç†å›ç­”
    with st.chat_message("assistant"):
        if not st.session_state.rag_pipeline:
            st.error("System not initialized. Please wait...")
        else:
            with st.spinner("Researching..."):
                try:
                    # ä½¿ç”¨RAG pipelineè·å–å›ç­”
                    response = st.session_state.rag_pipeline.ask(prompt)
                    
                    # æ·»åŠ å›ç­”åˆ°å†å²
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": response,
                        "citations": ["More detailed citations will be implemented"]  # å°†æ¥å¯ä»¥æ·»åŠ å®é™…å¼•ç”¨
                    })
                    
                    # æ˜¾ç¤ºå›ç­”
                    st.write(response)
                    
                except Exception as e:
                    st.error(f"Error generating response: {str(e)}")

# é¡µè„š
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    if st.button("Clear Conversation"):
        st.session_state.chat_history = []
        st.experimental_rerun()

with col2:
    if st.button("Export Chat"):
        # TODO: å®ç°å¯¼å‡ºåŠŸèƒ½
        st.info("Export feature coming soon!")
